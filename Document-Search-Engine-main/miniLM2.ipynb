{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç Multi-Document Search Engine with RAG\n",
        "\n",
        "This notebook implements a complete RAG (Retrieval-Augmented Generation) system that:\n",
        "- Searches across PDF, DOCX, and CSV documents\n",
        "- Uses intelligent routing to determine document type\n",
        "- Provides conversational answers using LLM\n",
        "\n",
        "**Model Details:**\n",
        "- Embeddings: `sentence-transformers/all-mpnet-base-v2` (768 dimensions)\n",
        "- LLM: `openai/gpt-oss-20b:free` via OpenRouter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment variables loaded\n",
            "‚úÖ API Key configured: gsk_M05EvH...KFW8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# Load API keys from .env file\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# Explicitly verify and set the GROQ_API_KEY\n",
        "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"‚ùå GROQ_API_KEY not found in .env file!\")\n",
        "\n",
        "# Ensure it's in the environment\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "\n",
        "print(\"‚úÖ Environment variables loaded\")\n",
        "print(f\"‚úÖ API Key configured: {GROQ_API_KEY[:10]}...{GROQ_API_KEY[-4:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "‚úÖ All libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# LangChain core\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "from langchain_community.document_loaders import CSVLoader, PyPDFLoader, Docx2txtLoader\n",
        "\n",
        "# LangChain core components\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# HuggingFace for embeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Utilities\n",
        "import glob\n",
        "from typing import List, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Initialize Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings model... (this may take a minute)\n",
            "‚úÖ Embedding model loaded successfully!\n",
            "   Embedding dimension: 768\n",
            "   Sample values: [0.04652438312768936, 0.003415079554542899, -0.014530852437019348, -0.033341292291879654, 0.03532654419541359]\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading embeddings model... (this may take a minute)\")\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # for cosine similarity\n",
        ")\n",
        "\n",
        "# Test the embeddings\n",
        "test_text = \"Hello World, how are you?\"\n",
        "test_embedding = embeddings.embed_query(test_text)\n",
        "print(f\"‚úÖ Embedding model loaded successfully!\")\n",
        "print(f\"   Embedding dimension: {len(test_embedding)}\")\n",
        "print(f\"   Sample values: {test_embedding[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize LLM (OpenRouter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LLM initialized successfully!\n",
            "   Model: llama-3.3-70b-versatile\n",
            "   Provider: Groq\n",
            "\n",
            "üß™ Testing LLM connection...\n",
            "   ‚úÖ LLM Test Response: Ready\n"
          ]
        }
      ],
      "source": [
        "# Initialize the LLM for routing and answering (Using Groq - FREE!)\n",
        "\n",
        "# Verify API key is loaded\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"‚ùå Run Step 1 first to load the API key!\")\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0.0,\n",
        "    api_key=GROQ_API_KEY,  # Explicit API key\n",
        "    model=\"llama-3.3-70b-versatile\",  # Fast & FREE!\n",
        ")\n",
        "\n",
        "print(\"‚úÖ LLM initialized successfully!\")\n",
        "print(f\"   Model: llama-3.3-70b-versatile\")\n",
        "print(f\"   Provider: Groq\")\n",
        "\n",
        "# Test the LLM with a simple call\n",
        "print(\"\\nüß™ Testing LLM connection...\")\n",
        "try:\n",
        "    test_response = llm.invoke(\"Say 'ready' in one word\")\n",
        "    print(f\"   ‚úÖ LLM Test Response: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå LLM Test Failed: {str(e)}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Load Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Loading documents...\n",
            "============================================================\n",
            "üìÑ Loading PDF: .\\iphone17.pdf\n",
            "üìù Loading DOCX: .\\f1info.docx\n",
            "üìä Loading CSV: .\\sales.csv\n",
            "\n",
            "============================================================\n",
            "Document Loading Summary\n",
            "============================================================\n",
            "  PDF: 7 documents\n",
            "  DOCX: 1 documents\n",
            "  CSV: 299 documents\n",
            "\n",
            "‚úÖ Total documents loaded: 307\n"
          ]
        }
      ],
      "source": [
        "def load_documents_by_type(directory: str = \".\") -> Dict[str, List[Document]]:\n",
        "    \"\"\"\n",
        "    Load all documents from directory, organized by type\n",
        "    Returns a dictionary with keys: 'pdf', 'docx', 'csv'\n",
        "    \"\"\"\n",
        "    documents_by_type = {\n",
        "        'pdf': [],\n",
        "        'docx': [],\n",
        "        'csv': []\n",
        "    }\n",
        "    \n",
        "    # Load PDF files\n",
        "    pdf_files = glob.glob(f\"{directory}/*.pdf\")\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"üìÑ Loading PDF: {pdf_file}\")\n",
        "        loader = PyPDFLoader(pdf_file)\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata['doc_type'] = 'pdf'\n",
        "        documents_by_type['pdf'].extend(docs)\n",
        "    \n",
        "    # Load DOCX files\n",
        "    docx_files = glob.glob(f\"{directory}/*.docx\")\n",
        "    for docx_file in docx_files:\n",
        "        print(f\"üìù Loading DOCX: {docx_file}\")\n",
        "        loader = Docx2txtLoader(docx_file)\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata['doc_type'] = 'docx'\n",
        "        documents_by_type['docx'].extend(docs)\n",
        "    \n",
        "    # Load CSV files\n",
        "    csv_files = glob.glob(f\"{directory}/*.csv\")\n",
        "    for csv_file in csv_files:\n",
        "        print(f\"üìä Loading CSV: {csv_file}\")\n",
        "        loader = CSVLoader(file_path=csv_file)\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata['doc_type'] = 'csv'\n",
        "        documents_by_type['csv'].extend(docs)\n",
        "    \n",
        "    return documents_by_type\n",
        "\n",
        "# Load all documents\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Loading documents...\")\n",
        "print(\"=\"*60)\n",
        "all_documents = load_documents_by_type(\".\")\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Document Loading Summary\")\n",
        "print(\"=\"*60)\n",
        "for doc_type, docs in all_documents.items():\n",
        "    if docs:\n",
        "        print(f\"  {doc_type.upper()}: {len(docs)} documents\")\n",
        "print(f\"\\n‚úÖ Total documents loaded: {sum(len(docs) for docs in all_documents.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating vector stores...\n",
            "  üî® Creating PDF vector store (7 docs)\n",
            "  üî® Creating DOCX vector store (1 docs)\n",
            "  üî® Creating CSV vector store (299 docs)\n",
            "\n",
            "‚úÖ Vector stores created for: ['pdf', 'docx', 'csv']\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating vector stores...\")\n",
        "vector_stores = {}\n",
        "retrievers = {}\n",
        "\n",
        "# Create vector store for PDFs\n",
        "if all_documents['pdf']:\n",
        "    print(f\"  üî® Creating PDF vector store ({len(all_documents['pdf'])} docs)\")\n",
        "    vector_stores['pdf'] = DocArrayInMemorySearch.from_documents(\n",
        "        all_documents['pdf'], \n",
        "        embeddings\n",
        "    )\n",
        "    retrievers['pdf'] = vector_stores['pdf'].as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Create vector store for DOCX files\n",
        "if all_documents['docx']:\n",
        "    print(f\"  üî® Creating DOCX vector store ({len(all_documents['docx'])} docs)\")\n",
        "    vector_stores['docx'] = DocArrayInMemorySearch.from_documents(\n",
        "        all_documents['docx'], \n",
        "        embeddings\n",
        "    )\n",
        "    retrievers['docx'] = vector_stores['docx'].as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Create vector store for CSV files\n",
        "if all_documents['csv']:\n",
        "    print(f\"  üî® Creating CSV vector store ({len(all_documents['csv'])} docs)\")\n",
        "    vector_stores['csv'] = DocArrayInMemorySearch.from_documents(\n",
        "        all_documents['csv'], \n",
        "        embeddings\n",
        "    )\n",
        "    retrievers['csv'] = vector_stores['csv'].as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "print(f\"\\n‚úÖ Vector stores created for: {list(retrievers.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create QA Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating QA chains...\n",
            "  ‚õìÔ∏è  Creating QA chain for PDF documents\n",
            "  ‚õìÔ∏è  Creating QA chain for DOCX documents\n",
            "  ‚õìÔ∏è  Creating QA chain for CSV documents\n",
            "\n",
            "‚úÖ QA chains created for: ['pdf', 'docx', 'csv']\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating QA chains...\")\n",
        "qa_chains = {}\n",
        "\n",
        "# Create a prompt template for QA\n",
        "qa_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\"\"\"\n",
        ")\n",
        "\n",
        "# Helper function to format docs\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "for doc_type, retriever in retrievers.items():\n",
        "    print(f\"  ‚õìÔ∏è  Creating QA chain for {doc_type.upper()} documents\")\n",
        "    \n",
        "    # Create a simple RAG chain using LCEL (LangChain Expression Language)\n",
        "    qa_chains[doc_type] = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | qa_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "print(f\"\\n‚úÖ QA chains created for: {list(qa_chains.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Configure Router"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Router configured with 3 document types\n",
            "   - pdf: The PDF document contains information about iPhone 17 series launch (September 2...\n",
            "   - docx: The Word document contains information about F1 Singapore Grand Prix 2025 (Octob...\n",
            "   - csv: The CSV document contains sales data with customer orders. Good for answering qu...\n"
          ]
        }
      ],
      "source": [
        "# Define retriever information for the router\n",
        "retriever_infos = []\n",
        "\n",
        "if 'pdf' in retrievers:\n",
        "    retriever_infos.append({\n",
        "        \"name\": \"pdf\",\n",
        "        \"description\": \"The PDF document contains information about iPhone 17 series launch (September 2025). Good for answering questions about iPhone 17 features, specifications, launch dates, pricing, and product details.\",\n",
        "        \"retriever\": retrievers['pdf']\n",
        "    })\n",
        "\n",
        "if 'docx' in retrievers:\n",
        "    retriever_infos.append({\n",
        "        \"name\": \"docx\",\n",
        "        \"description\": \"The Word document contains information about F1 Singapore Grand Prix 2025 (October 2025). Good for answering questions about F1 race, Grand Prix details, race results, and Singapore event information.\",\n",
        "        \"retriever\": retrievers['docx']\n",
        "    })\n",
        "\n",
        "if 'csv' in retrievers:\n",
        "    retriever_infos.append({\n",
        "        \"name\": \"csv\",\n",
        "        \"description\": \"The CSV document contains sales data with customer orders. Good for answering questions about sales records, orders, corporate segment, customer information, numerical data, and transaction details.\",\n",
        "        \"retriever\": retrievers['csv']\n",
        "    })\n",
        "\n",
        "print(f\"‚úÖ Router configured with {len(retriever_infos)} document types\")\n",
        "for info in retriever_infos:\n",
        "    print(f\"   - {info['name']}: {info['description'][:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Create Multi-Retrieval QA Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up intelligent router...\n",
            "\n",
            "============================================================\n",
            "‚úÖ SYSTEM READY!\n",
            "============================================================\n",
            "Available document types: ['pdf', 'docx', 'csv']\n",
            "\n",
            "You can now ask questions using: query_documents('your question')\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Simple routing logic using LLM classification\n",
        "print(\"Setting up intelligent router...\")\n",
        "\n",
        "# Router prompt to determine which document type to search\n",
        "router_template = \"\"\"Given the user question below, classify it to route to the most relevant document type.\n",
        "\n",
        "Available document types:\n",
        "- pdf: iPhone 17 series information (features, specs, launch, pricing)\n",
        "- docx: F1 Singapore Grand Prix 2025 information (race results, event details)\n",
        "- csv: Sales data with orders, customers, segments\n",
        "\n",
        "User question: {question}\n",
        "\n",
        "Respond with ONLY ONE WORD - either 'pdf', 'docx', or 'csv'. Nothing else.\n",
        "Classification:\"\"\"\n",
        "\n",
        "router_prompt = ChatPromptTemplate.from_template(router_template)\n",
        "router_chain = router_prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ SYSTEM READY!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Available document types: {list(retrievers.keys())}\")\n",
        "print(\"\\nYou can now ask questions using: query_documents('your question')\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Query Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_documents(user_query: str):\n",
        "    \"\"\"\n",
        "    Main query function with intelligent routing\n",
        "    \n",
        "    Args:\n",
        "        user_query: Your question (string)\n",
        "        \n",
        "    The router will analyze your question and route it to:\n",
        "        - PDF documents (for iPhone 17 info)\n",
        "        - DOCX documents (for F1 Singapore GP info)\n",
        "        - CSV files (for sales data analysis)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"USER QUERY: {user_query}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    try:\n",
        "        # Use router to determine which document type to search\n",
        "        doc_type = router_chain.invoke({\"question\": user_query}).strip().lower()\n",
        "        \n",
        "        print(f\"üéØ Routing to: {doc_type.upper()} documents\\n\")\n",
        "        \n",
        "        # Validate doc_type\n",
        "        if doc_type not in qa_chains:\n",
        "            print(f\"‚ö†Ô∏è  Warning: '{doc_type}' not found, using first available chain\")\n",
        "            doc_type = list(qa_chains.keys())[0]\n",
        "        \n",
        "        # Run the appropriate QA chain\n",
        "        answer = qa_chains[doc_type].invoke(user_query)\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"ANSWER:\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(answer)\n",
        "        print()\n",
        "        \n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Queries - Try These!\n",
        "\n",
        "Run the cell below to test the system with example queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "USER QUERY: Can you list me five corporate segment orders in the sales data?\n",
            "============================================================\n",
            "\n",
            "üéØ Routing to: CSV documents\n",
            "\n",
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "Here are five corporate segment orders in the sales data:\n",
            "\n",
            "1. Order ID: US-2017-124303, Customer Name: Fred Hopkins, Sales: 16.056\n",
            "2. Order ID: CA-2017-132976, Customer Name: Andrew Gjertsen, Sales: 11.648\n",
            "3. Order ID: US-2017-145366, Customer Name: Christine Abelman, Sales: 57.576\n",
            "4. Order ID: CA-2017-132976, Customer Name: Andrew Gjertsen, Sales: 18.176\n",
            "5. Order ID: US-2014-100853, Customer Name: Jennifer Braxton, Sales: 52.448\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Here are five corporate segment orders in the sales data:\\n\\n1. Order ID: US-2017-124303, Customer Name: Fred Hopkins, Sales: 16.056\\n2. Order ID: CA-2017-132976, Customer Name: Andrew Gjertsen, Sales: 11.648\\n3. Order ID: US-2017-145366, Customer Name: Christine Abelman, Sales: 57.576\\n4. Order ID: CA-2017-132976, Customer Name: Andrew Gjertsen, Sales: 18.176\\n5. Order ID: US-2014-100853, Customer Name: Jennifer Braxton, Sales: 52.448'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1: CSV Query\n",
        "query_documents(\"Can you list me five corporate segment orders in the sales data?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "USER QUERY: What are the main features of iPhone 17?\n",
            "============================================================\n",
            "\n",
            "üéØ Routing to: PDF documents\n",
            "\n",
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "The main features of the iPhone 17 include:\n",
            "\n",
            "1. A 6.3-inch Super Retina XDR display with ProMotion up to 120 Hz for smoother animations.\n",
            "2. The Ceramic Shield 2 front glass, which is claimed to be tougher with 3√ó better scratch resistance and reduced glare.\n",
            "3. A new camera system with all 48 MP rear cameras ‚Äî a Dual Fusion system (Main + Telephoto) plus a 48 MP Ultra Wide.\n",
            "4. A Center Stage front camera with support for up to 18 MP and improved video stabilization.\n",
            "5. Introduction of Dual Capture: simultaneous recording from front + rear cameras, natively in the Camera app.\n",
            "6. Powered by the A19 chip, built on a third-generation 3 nm node, with an upgraded 16-core Neural Engine and improved image signal processor.\n",
            "7. Storage options: base 256 GB and 512 GB, with Apple bumping the entry storage to 256 GB (double last year).\n",
            "8. Color options: black, lavender, mist blue, sage, and white.\n",
            "\n",
            "These features position the iPhone 17 as a solid all-round upgrade, with meaningful enhancements in display, camera, and durability.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The main features of the iPhone 17 include:\\n\\n1. A 6.3-inch Super Retina XDR display with ProMotion up to 120 Hz for smoother animations.\\n2. The Ceramic Shield 2 front glass, which is claimed to be tougher with 3√ó better scratch resistance and reduced glare.\\n3. A new camera system with all 48 MP rear cameras ‚Äî a Dual Fusion system (Main + Telephoto) plus a 48 MP Ultra Wide.\\n4. A Center Stage front camera with support for up to 18 MP and improved video stabilization.\\n5. Introduction of Dual Capture: simultaneous recording from front + rear cameras, natively in the Camera app.\\n6. Powered by the A19 chip, built on a third-generation 3 nm node, with an upgraded 16-core Neural Engine and improved image signal processor.\\n7. Storage options: base 256 GB and 512 GB, with Apple bumping the entry storage to 256 GB (double last year).\\n8. Color options: black, lavender, mist blue, sage, and white.\\n\\nThese features position the iPhone 17 as a solid all-round upgrade, with meaningful enhancements in display, camera, and durability.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2: PDF Query\n",
        "query_documents(\"What are the main features of iPhone 17?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "USER QUERY: Who won the Singapore Grand Prix 2025?\n",
            "============================================================\n",
            "\n",
            "üéØ Routing to: DOCX documents\n",
            "\n",
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "George Russell won the 2025 Singapore Grand Prix.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'George Russell won the 2025 Singapore Grand Prix.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 3: DOCX Query\n",
        "query_documents(\"Who won the Singapore Grand Prix 2025?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Custom Queries\n",
        "\n",
        "Use the cell below to ask your own questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "USER QUERY: Your question here\n",
            "============================================================\n",
            "\n",
            "üéØ Routing to: PDF documents\n",
            "\n",
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "You haven't asked a question yet. Please go ahead and ask your question, and I'll do my best to answer it based on the provided context. If I don't know the answer, I'll let you know that as well.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"You haven't asked a question yet. Please go ahead and ask your question, and I'll do my best to answer it based on the provided context. If I don't know the answer, I'll let you know that as well.\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ask your own question here\n",
        "my_question = \"Your question here\"\n",
        "\n",
        "query_documents(my_question)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
