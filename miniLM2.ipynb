{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç Multi-Document Search Engine with RAG\n",
        "\n",
        "This notebook implements a complete RAG (Retrieval-Augmented Generation) system that:\n",
        "- Searches across PDF, DOCX, and CSV documents\n",
        "- Uses intelligent routing to determine document type\n",
        "- Provides conversational answers using LLM\n",
        "\n",
        "**Model Details:**\n",
        "- Embeddings: `sentence-transformers/all-mpnet-base-v2` (768 dimensions)\n",
        "- LLM: `openai/gpt-oss-20b:free` via OpenRouter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# Load API keys from .env file\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# Explicitly verify and set the GROQ_API_KEY\n",
        "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"‚ùå GROQ_API_KEY not found in .env file!\")\n",
        "\n",
        "# Ensure it's in the environment\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "\n",
        "print(\"‚úÖ Environment variables loaded\")\n",
        "print(f\"‚úÖ API Key configured: {GROQ_API_KEY[:10]}...{GROQ_API_KEY[-4:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangChain core\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "from langchain_community.document_loaders import CSVLoader, PyPDFLoader, Docx2txtLoader\n",
        "\n",
        "# LangChain core components\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# HuggingFace for embeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Utilities\n",
        "import glob\n",
        "from typing import List, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Initialize Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading embeddings model... (this may take a minute)\")\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # for cosine similarity\n",
        ")\n",
        "\n",
        "# Test the embeddings\n",
        "test_text = \"Hello World, how are you?\"\n",
        "test_embedding = embeddings.embed_query(test_text)\n",
        "print(f\"‚úÖ Embedding model loaded successfully!\")\n",
        "print(f\"   Embedding dimension: {len(test_embedding)}\")\n",
        "print(f\"   Sample values: {test_embedding[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize LLM (OpenRouter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the LLM for routing and answering (Using Groq - FREE!)\n",
        "\n",
        "# Verify API key is loaded\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"‚ùå Run Step 1 first to load the API key!\")\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0.0,\n",
        "    api_key=GROQ_API_KEY,  # Explicit API key\n",
        "    model=\"llama-3.3-70b-versatile\",  # Fast & FREE!\n",
        ")\n",
        "\n",
        "print(\"‚úÖ LLM initialized successfully!\")\n",
        "print(f\"   Model: llama-3.3-70b-versatile\")\n",
        "print(f\"   Provider: Groq\")\n",
        "\n",
        "# Test the LLM with a simple call\n",
        "print(\"\\nüß™ Testing LLM connection...\")\n",
        "try:\n",
        "    test_response = llm.invoke(\"Say 'ready' in one word\")\n",
        "    print(f\"   ‚úÖ LLM Test Response: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå LLM Test Failed: {str(e)}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Load Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_documents_by_type(directory: str = \".\") -> Dict[str, List[Document]]:\n",
        "    \"\"\"\n",
        "    Load all documents from directory, organized by type\n",
        "    Returns a dictionary with keys: 'pdf', 'docx', 'csv'\n",
        "    \"\"\"\n",
        "    documents_by_type = {\n",
        "        'pdf': [],\n",
        "        'docx': [],\n",
        "        'csv': []\n",
        "    }\n",
        "    \n",
        "    # Load PDF files\n",
        "    pdf_files = glob.glob(f\"{directory}/*.pdf\")\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"üìÑ Loading PDF: {pdf_file}\")\n",
        "        loader = PyPDFLoader(pdf_file)\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata['doc_type'] = 'pdf'\n",
        "        documents_by_type['pdf'].extend(docs)\n",
        "    \n",
        "    # Load DOCX files\n",
        "    docx_files = glob.glob(f\"{directory}/*.docx\")\n",
        "    for docx_file in docx_files:\n",
        "        print(f\"üìù Loading DOCX: {docx_file}\")\n",
        "        loader = Docx2txtLoader(docx_file)\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata['doc_type'] = 'docx'\n",
        "        documents_by_type['docx'].extend(docs)\n",
        "    \n",
        "    # Load CSV files\n",
        "    csv_files = glob.glob(f\"{directory}/*.csv\")\n",
        "    for csv_file in csv_files:\n",
        "        print(f\"üìä Loading CSV: {csv_file}\")\n",
        "        loader = CSVLoader(file_path=csv_file)\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata['doc_type'] = 'csv'\n",
        "        documents_by_type['csv'].extend(docs)\n",
        "    \n",
        "    return documents_by_type\n",
        "\n",
        "# Load all documents\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Loading documents...\")\n",
        "print(\"=\"*60)\n",
        "all_documents = load_documents_by_type(\".\")\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Document Loading Summary\")\n",
        "print(\"=\"*60)\n",
        "for doc_type, docs in all_documents.items():\n",
        "    if docs:\n",
        "        print(f\"  {doc_type.upper()}: {len(docs)} documents\")\n",
        "print(f\"\\n‚úÖ Total documents loaded: {sum(len(docs) for docs in all_documents.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Creating vector stores...\")\n",
        "vector_stores = {}\n",
        "retrievers = {}\n",
        "\n",
        "# Create vector store for PDFs\n",
        "if all_documents['pdf']:\n",
        "    print(f\"  üî® Creating PDF vector store ({len(all_documents['pdf'])} docs)\")\n",
        "    vector_stores['pdf'] = DocArrayInMemorySearch.from_documents(\n",
        "        all_documents['pdf'], \n",
        "        embeddings\n",
        "    )\n",
        "    retrievers['pdf'] = vector_stores['pdf'].as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Create vector store for DOCX files\n",
        "if all_documents['docx']:\n",
        "    print(f\"  üî® Creating DOCX vector store ({len(all_documents['docx'])} docs)\")\n",
        "    vector_stores['docx'] = DocArrayInMemorySearch.from_documents(\n",
        "        all_documents['docx'], \n",
        "        embeddings\n",
        "    )\n",
        "    retrievers['docx'] = vector_stores['docx'].as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Create vector store for CSV files\n",
        "if all_documents['csv']:\n",
        "    print(f\"  üî® Creating CSV vector store ({len(all_documents['csv'])} docs)\")\n",
        "    vector_stores['csv'] = DocArrayInMemorySearch.from_documents(\n",
        "        all_documents['csv'], \n",
        "        embeddings\n",
        "    )\n",
        "    retrievers['csv'] = vector_stores['csv'].as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "print(f\"\\n‚úÖ Vector stores created for: {list(retrievers.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create QA Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Creating QA chains...\")\n",
        "qa_chains = {}\n",
        "\n",
        "# Create a prompt template for QA\n",
        "qa_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\"\"\"\n",
        ")\n",
        "\n",
        "# Helper function to format docs\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "for doc_type, retriever in retrievers.items():\n",
        "    print(f\"  ‚õìÔ∏è  Creating QA chain for {doc_type.upper()} documents\")\n",
        "    \n",
        "    # Create a simple RAG chain using LCEL (LangChain Expression Language)\n",
        "    qa_chains[doc_type] = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | qa_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "print(f\"\\n‚úÖ QA chains created for: {list(qa_chains.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Configure Router"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define retriever information for the router\n",
        "retriever_infos = []\n",
        "\n",
        "if 'pdf' in retrievers:\n",
        "    retriever_infos.append({\n",
        "        \"name\": \"pdf\",\n",
        "        \"description\": \"The PDF document contains information about iPhone 17 series launch (September 2025). Good for answering questions about iPhone 17 features, specifications, launch dates, pricing, and product details.\",\n",
        "        \"retriever\": retrievers['pdf']\n",
        "    })\n",
        "\n",
        "if 'docx' in retrievers:\n",
        "    retriever_infos.append({\n",
        "        \"name\": \"docx\",\n",
        "        \"description\": \"The Word document contains information about F1 Singapore Grand Prix 2025 (October 2025). Good for answering questions about F1 race, Grand Prix details, race results, and Singapore event information.\",\n",
        "        \"retriever\": retrievers['docx']\n",
        "    })\n",
        "\n",
        "if 'csv' in retrievers:\n",
        "    retriever_infos.append({\n",
        "        \"name\": \"csv\",\n",
        "        \"description\": \"The CSV document contains sales data with customer orders. Good for answering questions about sales records, orders, corporate segment, customer information, numerical data, and transaction details.\",\n",
        "        \"retriever\": retrievers['csv']\n",
        "    })\n",
        "\n",
        "print(f\"‚úÖ Router configured with {len(retriever_infos)} document types\")\n",
        "for info in retriever_infos:\n",
        "    print(f\"   - {info['name']}: {info['description'][:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Create Multi-Retrieval QA Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple routing logic using LLM classification\n",
        "print(\"Setting up intelligent router...\")\n",
        "\n",
        "# Router prompt to determine which document type to search\n",
        "router_template = \"\"\"Given the user question below, classify it to route to the most relevant document type.\n",
        "\n",
        "Available document types:\n",
        "- pdf: iPhone 17 series information (features, specs, launch, pricing)\n",
        "- docx: F1 Singapore Grand Prix 2025 information (race results, event details)\n",
        "- csv: Sales data with orders, customers, segments\n",
        "\n",
        "User question: {question}\n",
        "\n",
        "Respond with ONLY ONE WORD - either 'pdf', 'docx', or 'csv'. Nothing else.\n",
        "Classification:\"\"\"\n",
        "\n",
        "router_prompt = ChatPromptTemplate.from_template(router_template)\n",
        "router_chain = router_prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ SYSTEM READY!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Available document types: {list(retrievers.keys())}\")\n",
        "print(\"\\nYou can now ask questions using: query_documents('your question')\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Query Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_documents(user_query: str):\n",
        "    \"\"\"\n",
        "    Main query function with intelligent routing\n",
        "    \n",
        "    Args:\n",
        "        user_query: Your question (string)\n",
        "        \n",
        "    The router will analyze your question and route it to:\n",
        "        - PDF documents (for iPhone 17 info)\n",
        "        - DOCX documents (for F1 Singapore GP info)\n",
        "        - CSV files (for sales data analysis)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"USER QUERY: {user_query}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    try:\n",
        "        # Use router to determine which document type to search\n",
        "        doc_type = router_chain.invoke({\"question\": user_query}).strip().lower()\n",
        "        \n",
        "        print(f\"üéØ Routing to: {doc_type.upper()} documents\\n\")\n",
        "        \n",
        "        # Validate doc_type\n",
        "        if doc_type not in qa_chains:\n",
        "            print(f\"‚ö†Ô∏è  Warning: '{doc_type}' not found, using first available chain\")\n",
        "            doc_type = list(qa_chains.keys())[0]\n",
        "        \n",
        "        # Run the appropriate QA chain\n",
        "        answer = qa_chains[doc_type].invoke(user_query)\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"ANSWER:\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(answer)\n",
        "        print()\n",
        "        \n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Queries - Try These!\n",
        "\n",
        "Run the cell below to test the system with example queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: CSV Query\n",
        "query_documents(\"Can you list me five corporate segment orders in the sales data?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: PDF Query\n",
        "query_documents(\"What are the main features of iPhone 17?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: DOCX Query\n",
        "query_documents(\"Who won the Singapore Grand Prix 2025?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Custom Queries\n",
        "\n",
        "Use the cell below to ask your own questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ask your own question here\n",
        "my_question = \"Your question here\"\n",
        "\n",
        "query_documents(my_question)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}